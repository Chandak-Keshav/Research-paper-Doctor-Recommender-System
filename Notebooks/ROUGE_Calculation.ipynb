{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load CSV files\n",
    "patients_df = pd.read_csv(\"../filtered_specialists.csv\")  # All rows processed\n",
    "# patients_df=patients_df.head(10)\n",
    "specialities_df = pd.read_csv(\"specialist_description.csv\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    doc = nlp(text)\n",
    "    weighted_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Skip stopwords and punctuation\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        \n",
    "        # Assign weights based on POS tags\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"]:  # Nouns and proper nouns\n",
    "            weight = 1.5  # Higher weight\n",
    "        elif token.pos_ in [\"ADJ\", \"ADV\"]:  # Adjectives and adverbs\n",
    "            weight = 1.2\n",
    "        elif token.pos_ in [\"VERB\"]:  # Verbs\n",
    "            weight = 0.8  # Verbs excluded since int(0.8) = 0\n",
    "        elif token.pos_ in [\"ADP\"]:  # Prepositions\n",
    "            weight = 0.5  # Prepositions excluded since int(0.5) = 0\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        \n",
    "        # Append token based on integer weight\n",
    "        weighted_tokens.extend([token.lemma_.lower()] * int(weight))\n",
    "    \n",
    "    return \" \".join(weighted_tokens)\n",
    "\n",
    "# Calculate weighted ROUGE scores\n",
    "def calculate_rouge_scores(speciality, symptom_desc, diagnosis, speciality_desc):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Preprocess texts\n",
    "    symptom_desc_processed = preprocess_text(symptom_desc)\n",
    "    diagnosis_processed = preprocess_text(diagnosis)\n",
    "    speciality_desc_processed = preprocess_text(speciality_desc)\n",
    "    spec_process = preprocess_text(speciality)\n",
    "    \n",
    "    # Concatenate with space (corrected from \"/n\")\n",
    "    patient_text = symptom_desc_processed + \" \" + diagnosis_processed\n",
    "    speciality_text = spec_process + \" \" + speciality_desc_processed\n",
    "    \n",
    "    scores = scorer.score(patient_text, speciality_text)\n",
    "    rouge1_score = scores['rouge1'].fmeasure\n",
    "    rougeL_score = scores['rougeL'].fmeasure\n",
    "    \n",
    "    # Weighted scores\n",
    "    weighted_rouge1 = rouge1_score * 0.7\n",
    "    weighted_rougeL = rougeL_score * 0.3\n",
    "    \n",
    "    # Combined score\n",
    "    combined_score = weighted_rouge1 + weighted_rougeL\n",
    "    return combined_score\n",
    "\n",
    "# Find the best speciality\n",
    "def find_best_speciality(symptom_desc, diagnosis, specialities_df):\n",
    "    best_speciality = None\n",
    "    best_score = -1.0\n",
    "    \n",
    "    for _, row in specialities_df.iterrows():\n",
    "        speciality = row['Speciality']\n",
    "        speciality_desc = row['Description']\n",
    "        \n",
    "        score = calculate_rouge_scores(speciality, symptom_desc, diagnosis, speciality_desc)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_speciality = speciality\n",
    "    \n",
    "    return best_speciality, best_score\n",
    "\n",
    "# Assign predicted specialities to DataFrame\n",
    "def assign_predicted_speciality(patients_df, specialities_df):\n",
    "    for index, row in patients_df.iterrows():\n",
    "        symptom_desc = row['Patient']\n",
    "        diagnosis = row['Description']\n",
    "        best_speciality, _ = find_best_speciality(symptom_desc, diagnosis, specialities_df)\n",
    "        patients_df.at[index, 'Predicted_Speciality'] = best_speciality\n",
    "    return patients_df\n",
    "\n",
    "# Calculate accuracy (optional)\n",
    "def calculate_accuracy(patients_df):\n",
    "    correct_predictions = (patients_df['Predicted_Speciality'].str.lower() == patients_df['Specialist'].str.lower()).sum()\n",
    "    total_predictions = len(patients_df)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Main execution\n",
    "# Assign predicted specialities\n",
    "patients_df = assign_predicted_speciality(patients_df, specialities_df)\n",
    "\n",
    "# Save to new CSV with all original data plus predicted speciality\n",
    "patients_df.to_csv(\"patients_with_predicted_speciality.csv\", index=False)\n",
    "\n",
    "# Optional: Calculate and print accuracy\n",
    "accuracy = calculate_accuracy(patients_df)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load CSV files\n",
    "patients_df = pd.read_csv(\"../filtered_specialists.csv\")  # All rows processed\n",
    "specialities_df = pd.read_csv(\"specialist_description.csv\")\n",
    "\n",
    "# Preprocessing function to extract nouns, adjectives, and adverbs\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Extract only nouns, adjectives, and adverbs\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\", \"ADJ\", \"ADV\"] and not token.is_stop and not token.is_punct:\n",
    "            filtered_tokens.append(token.lemma_.lower())\n",
    "    \n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "def calculate_rouge_scores(speciality, symptom_desc, diagnosis, speciality_desc):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Preprocess texts\n",
    "    symptom_desc_processed = preprocess_text(symptom_desc)\n",
    "    diagnosis_processed = preprocess_text(diagnosis)\n",
    "    speciality_desc_processed = preprocess_text(speciality_desc)\n",
    "    spec_process = preprocess_text(speciality)\n",
    "    \n",
    "    # Concatenate with space\n",
    "    patient_text = symptom_desc_processed + \" \" + diagnosis_processed\n",
    "    speciality_text = spec_process + \" \" + speciality_desc_processed\n",
    "    \n",
    "    scores = scorer.score(patient_text, speciality_text)\n",
    "    rouge1_score = scores['rouge1'].fmeasure\n",
    "    rougeL_score = scores['rougeL'].fmeasure\n",
    "    \n",
    "    # Combined score (you can adjust weights or use equal weights)\n",
    "    combined_score = (rouge1_score + rougeL_score) / 2  # Simple average\n",
    "    return combined_score\n",
    "\n",
    "# Find the best speciality\n",
    "def find_best_speciality(symptom_desc, diagnosis, specialities_df):\n",
    "    best_speciality = None\n",
    "    best_score = -1.0\n",
    "    \n",
    "    for _, row in specialities_df.iterrows():\n",
    "        speciality = row['Speciality']\n",
    "        speciality_desc = row['Description']\n",
    "        \n",
    "        score = calculate_rouge_scores(speciality, symptom_desc, diagnosis, speciality_desc)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_speciality = speciality\n",
    "    \n",
    "    return best_speciality, best_score\n",
    "\n",
    "# Assign predicted specialities to DataFrame\n",
    "def assign_predicted_speciality(patients_df, specialities_df):\n",
    "    for index, row in patients_df.iterrows():\n",
    "        symptom_desc = row['Patient']\n",
    "        diagnosis = row['Description']\n",
    "        best_speciality, _ = find_best_speciality(symptom_desc, diagnosis, specialities_df)\n",
    "        patients_df.at[index, 'Predicted_Speciality'] = best_speciality\n",
    "    return patients_df\n",
    "\n",
    "# Calculate accuracy (optional)\n",
    "def calculate_accuracy(patients_df):\n",
    "    correct_predictions = (patients_df['Predicted_Speciality'].str.lower() == patients_df['Specialist'].str.lower()).sum()\n",
    "    total_predictions = len(patients_df)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Main execution\n",
    "patients_df = assign_predicted_speciality(patients_df, specialities_df)\n",
    "\n",
    "# Save to new CSV with all original data plus predicted speciality\n",
    "patients_df.to_csv(\"patients_with_predicted_speciality.csv\", index=False)\n",
    "\n",
    "# Optional: Calculate and print accuracy\n",
    "accuracy = calculate_accuracy(patients_df)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "import spacy\n",
    "from itertools import product\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load your CSV files\n",
    "patients_df = pd.read_csv(\"../filtered_specialists.csv\")  # Updated path\n",
    "# patients_df = patients_df.head(10)\n",
    "specialities_df = pd.read_csv(\"specialist_description.csv\")  # Updated path\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "patients_df['Patient'] = patients_df['Patient'].fillna('')\n",
    "patients_df['Description'] = patients_df['Description'].fillna('')\n",
    "patients_df['Specialist'] = patients_df['Specialist'].fillna('')\n",
    "specialities_df['Speciality'] = specialities_df['Speciality'].fillna('')\n",
    "specialities_df['Description'] = specialities_df['Description'].fillna('')\n",
    "specialities_df['Subspeciality'] = specialities_df['Subspeciality'].fillna('')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    doc = nlp(text)\n",
    "    weighted_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Skip stopwords and punctuation\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        \n",
    "        # Assign weights based on POS tags\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"]:  # Nouns and proper nouns\n",
    "            weight = 1.5  # Higher weight for nouns\n",
    "        elif token.pos_ in [\"ADJ\", \"ADV\"]:  # Adjectives and adverbs\n",
    "            weight = 1.2  # Slightly higher weight for adjectives and adverbs\n",
    "        elif token.pos_ in [\"VERB\"]:  # Verbs\n",
    "            weight = 0.8  # Lower weight for verbs\n",
    "        elif token.pos_ in [\"ADP\"]:  # Prepositions\n",
    "            weight = 0.5  # Much lower weight for prepositions\n",
    "        else:\n",
    "            weight = 1.0  # Default weight for other tokens\n",
    "        \n",
    "        # Append the token multiple times based on its weight\n",
    "        weighted_tokens.extend([token.lemma_.lower()] * int(weight))\n",
    "    \n",
    "    return \" \".join(weighted_tokens)\n",
    "\n",
    "# Calculate weighted ROUGE scores for a given symptom, diagnosis, and speciality description\n",
    "def calculate_rouge_scores(symptom_desc, diagnosis, speciality_desc, subspeciality_desc, rouge1_weight, rougeL_weight):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Preprocess texts\n",
    "    symptom_desc_processed = preprocess_text(symptom_desc)\n",
    "    diagnosis_processed = preprocess_text(diagnosis)\n",
    "    speciality_desc_processed = preprocess_text(speciality_desc)\n",
    "    subspeciality_desc_processed = preprocess_text(subspeciality_desc)\n",
    "    \n",
    "    # Calculate ROUGE-1 and ROUGE-L scores\n",
    "    rouge1_score = scorer.score(symptom_desc_processed + \"/n\" + diagnosis_processed, speciality_desc_processed + \"/n\" + subspeciality_desc_processed)['rouge1'].fmeasure\n",
    "    rougeL_score = scorer.score(symptom_desc_processed + \"/n\" + diagnosis_processed, speciality_desc_processed + \"/n\" + subspeciality_desc_processed)['rougeL'].fmeasure\n",
    "    \n",
    "    # Weighted scores (adjust weights as needed)\n",
    "    weighted_rouge1 = rouge1_score * rouge1_weight\n",
    "    weighted_rougeL = rougeL_score * rougeL_weight\n",
    "    \n",
    "    # Combined weighted score\n",
    "    combined_score = weighted_rouge1 + weighted_rougeL\n",
    "    return combined_score\n",
    "\n",
    "# Find the best speciality based on ROUGE scores\n",
    "def find_best_speciality(symptom_desc, diagnosis, specialities_df, rouge1_weight, rougeL_weight):\n",
    "    best_speciality = \"\"\n",
    "    best_score = -1.0\n",
    "    \n",
    "    for _, row in specialities_df.iterrows():\n",
    "        speciality = row['Speciality']\n",
    "        speciality_desc = row['Description']\n",
    "        subspeciality_desc = row['Subspeciality']\n",
    "        score = 0.0\n",
    "        # Calculate ROUGE score for this speciality\n",
    "        score = calculate_rouge_scores(symptom_desc, diagnosis, speciality_desc, subspeciality_desc, rouge1_weight, rougeL_weight)\n",
    "        \n",
    "        # Update best speciality if this score is higher\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_speciality = speciality\n",
    "    best_speciality = str(best_speciality)\n",
    "    return best_speciality\n",
    "\n",
    "# Calculate accuracy based on benchmark speciality\n",
    "def calculate_accuracy(patients_df, specialities_df, rouge1_weight, rougeL_weight):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(patients_df)\n",
    "    \n",
    "    for index, row in patients_df.iterrows():\n",
    "        symptom_desc = row['Patient']\n",
    "        diagnosis = row['Description']\n",
    "        benchmark_speciality = row['Specialist']\n",
    "        # Find the best speciality for this patient\n",
    "        best_speciality = find_best_speciality(symptom_desc, diagnosis, specialities_df, rouge1_weight, rougeL_weight)\n",
    "        \n",
    "        # Compare with benchmark speciality\n",
    "        if best_speciality == benchmark_speciality:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "def find_best_weights(patients_df, specialities_df):\n",
    "    best_accuracy = -1\n",
    "    best_weights = (0, 0)\n",
    "    \n",
    "    # Iterate through all possible weight combinations (0.1 to 0.9)\n",
    "    for rouge1_weight, rougeL_weight in product([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], repeat=2):\n",
    "        # Ensure the weights sum to 1\n",
    "        if abs(rouge1_weight + rougeL_weight - 1.0) > 1e-6:\n",
    "            continue\n",
    "        \n",
    "        # Calculate accuracy for this weight combination\n",
    "        accuracy = calculate_accuracy(patients_df, specialities_df, rouge1_weight, rougeL_weight)\n",
    "        \n",
    "        # Update best weights if this accuracy is higher\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_weights = (rouge1_weight, rougeL_weight)\n",
    "    \n",
    "    return best_weights, best_accuracy\n",
    "\n",
    "# Calculate and print accuracy\n",
    "best_weights, best_accuracy = find_best_weights(patients_df, specialities_df)\n",
    "print(f\"Best weights: ROUGE-1 = {best_weights[0]}, ROUGE-L = {best_weights[1]}\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
